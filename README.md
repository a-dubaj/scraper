# Scraper
[![CI Build](https://github.com/a-dubaj/scraper/actions/workflows/build.yml/badge.svg)](https://github.com/a-dubaj/scraper/actions/workflows/build.yml)
![Node Version](https://img.shields.io/badge/node-%3E%3D20.0.0-brightgreen)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
![Prettier](https://img.shields.io/badge/code%20style-prettier-ff69b4.svg)
![npm version](https://img.shields.io/npm/v/scraper)

## Overview

This project uses [Crawlee](https://crawlee.io/docs) to handle the heavy-lifting of scraping websites. 
The application is designed to efficiently gather and process data from various web sources.

## Prerequisites

Before you begin, ensure you have met the following requirements:
- `Node.js` installed on your machine
- A package manager `(npm, pnpm, or yarn)` installed

## Installation

1. Clone the repository to your local machine:
   ```bash
   git clone <repository-url>
   cd <repository-directory>
   ```
   
2. Install all dependencies
    ```bash
    npm i (recommended)
   ```

## After all the dependencies are installed you can start the scraper with.

# Start the development server
   ```bash
    npm run start
   ```

Then entry point for the application is in the `main.ts` file.